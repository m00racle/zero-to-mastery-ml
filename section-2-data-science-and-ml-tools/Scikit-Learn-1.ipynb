{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35e261dc",
   "metadata": {},
   "source": [
    "# SCIKIT LEARN WORKFLOW\n",
    "## END TO END SCIKIT LEARN WORKFLOW\n",
    "\n",
    "What is end to end means? \n",
    "\n",
    "One thing to note though Scikit Learn is such big library thus only call what you need will be a better approach to practical use.\n",
    "\n",
    "### Random Forest Classifier Workflow for Classifying Heart Disease.\n",
    "#### 1. Get the data ready\n",
    "I will use the heart disease data. Remember that it was stored in csv format. First I need to import it first. Pandas will be the appropriate library to get and process the data to form Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aafb8c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data heart-disease.csv\n",
    "import pandas as pd\n",
    "heart_disease_data = pd.read_csv('../data/heart-disease.csv')\n",
    "heart_disease_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba22bed",
   "metadata": {},
   "source": [
    "***NOTE***\n",
    "The heart_disease_data consist of all patient characteristics except for the target column. Target column is the end result whether the patient has heart_disease or not and we want to seek the connection with each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157b92dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we need to separate the target column from other data\n",
    "x_data = heart_disease_data.drop('target', axis=1)\n",
    "x_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18946443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now the target label will be in the y_data\n",
    "y_data = heart_disease_data['target']\n",
    "y_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b014306",
   "metadata": {},
   "source": [
    "***NOTE:***\n",
    "now I need to split the data frame in the x_data and y_data to do this I will use the scikit learn libs\n",
    "\n",
    "The way to import is a bit different since it is named sklearn thus to import I need import sklearn.\n",
    "\n",
    "Now as this library is quite bid I need to be specific. This time it is model_selection to be exact I want to randomly split the data frame heart_disease_data y_data and x_data. I will use the train_test_split library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9383de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# just to be safe if we need to handle some matrices I will import numpy as well\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be25184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227, 13), (227,), (76, 13), (76,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data)\n",
    "# let's test the result but since too big I will just validate each size\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee8a7a7",
   "metadata": {},
   "source": [
    "***NOTE:***\n",
    "The data (shape) above is important. \n",
    "\n",
    "I need to validatae that the x_train and y_train first size is the same (in this case 227).\n",
    "\n",
    "The same case is true for the x_test and y_test (in this case 76)\n",
    "\n",
    "It means will be 227 data for train and 76 for testing that chosen randomly.\n",
    "\n",
    "#### 2. Choose the model and hyperparameters\n",
    "Now this is the very heart of the Scikit Learn. A variety of models or in machine learning is known as classifiers. However, in Scikit documentation it is more commonly known as estimators. \n",
    "\n",
    "TODO So what is hyperparameters??\n",
    "\n",
    "Next we will use Random Forest Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=forest#sklearn.ensemble.RandomForestClassifier\n",
    "\n",
    " learn about Random Forest Classifier model: https://en.wikipedia.org/wiki/Random_forest\n",
    " It is said that this is part of the ensemble learning method thus it is put in the Sklearn ensemble libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a7c674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Random Forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# too long the name thus better put it into a variable\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94a51f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58510652",
   "metadata": {},
   "source": [
    "#### 3. Fit the model to the data and use it to make predictions\n",
    "Fitting the model on the data involves passing it the data and asking it to figure out the patterns.\n",
    "\n",
    "If there are labels (supervised learning), the model tries to work out the relationship between the data and the labels.\n",
    "\n",
    "If there are no labels (unsupervised learning), the model tries to find patterns and group similar samples together.\n",
    "\n",
    "First I need to build the forest of trees model from the training set, in this case is **x_train and y_train.**\n",
    "\n",
    "Read more about the forest of the random forest classifier's fit method: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce46420f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making random forest classifier \n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7513796f",
   "metadata": {},
   "source": [
    "***NOTE:***\n",
    "This clf.fit does not need to be stored in variable. I think it will just use the clf object to store the data from both side of randomly selected train data. \n",
    "\n",
    "\n",
    "Here clf = RandomForestClassifier is an **object**. It is just like the **DataFrame** in Pandas. You can modify directly the instatiation of this DataFrame (in this case heart_disease_data) which you can cut, process, etc. \n",
    "\n",
    "#### Use the model to make a prediction\n",
    "The whole point of training a machine learning model is to use it to make some kine of prediction in the future. \n",
    "\n",
    "Once our model instance is trained, you can use the predict() method to predict a target value given a set of features. In other words, use the model, along with some unlabelled data to predict the label.\n",
    "\n",
    "***CAUTION***: data you predict on has to be in the same shape as data you trained on.\n",
    "\n",
    "Fortunately we already have the correct shape since we built our train and test data randomly using the Scikit Learn **train_test_split()** function. This will ensure the x_train and x_test will be the same shape. (We already verified this above), emphasis in the number of column (in this case the second in the shape function output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e3fe5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "295   63    1   0       140   187    0        0      144      1      4.0   \n",
       "63    41    1   1       135   203    0        1      132      0      0.0   \n",
       "286   59    1   3       134   204    0        1      162      0      0.8   \n",
       "117   56    1   3       120   193    0        0      162      0      1.9   \n",
       "231   57    1   0       165   289    1        0      124      0      1.0   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "173   58    1   2       132   224    0        0      173      0      3.2   \n",
       "193   60    1   0       145   282    0        0      142      1      2.8   \n",
       "172   58    1   1       120   284    0        0      160      0      1.8   \n",
       "19    69    0   3       140   239    0        1      151      0      1.8   \n",
       "216   62    0   2       130   263    0        1       97      0      1.2   \n",
       "\n",
       "     slope  ca  thal  \n",
       "295      2   2     3  \n",
       "63       1   0     1  \n",
       "286      2   2     2  \n",
       "117      1   0     3  \n",
       "231      1   3     3  \n",
       "..     ...  ..   ...  \n",
       "173      2   2     3  \n",
       "193      1   2     3  \n",
       "172      1   0     2  \n",
       "19       2   2     2  \n",
       "216      1   1     3  \n",
       "\n",
       "[76 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to verify\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d074cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now using the predict method to make prediction onf the test data \n",
    "y_preds = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c411ce5",
   "metadata": {},
   "source": [
    "#### 4. Evaluate the model\n",
    "Now we've made some predictions (y_preds). we can start to use some more Scikit-Learn methods to figure out how good our models is. \n",
    "\n",
    "Each model or estimator has built-in score method. This method compares how well the model was able to learn the patterns between the features and labels. In other words, it returns how accurate your model is.\n",
    "\n",
    "Using Random Forest Classifier score method. \n",
    "\n",
    "**score(X, y[, sample_weight])** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.score\n",
    "\n",
    "Return the mean accuracy on the given test data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "769861c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f2dcbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8026315789473685"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b561c47e",
   "metadata": {},
   "source": [
    "***NOTE:*** this numbers are the mean accuracy between two data set. After using the predictin model we can use the model on the test data sets. \n",
    "\n",
    "#### use the additional evaluation methods and also libs for reporting\n",
    "This is part of the metrics libs of the sklearn. \n",
    "\n",
    "See the [Metrics and scoring: quantifying the quality of predictions](https://scikit-learn.org/stable/modules/model_evaluation.html#model-evaluation) section and the Pairwise metrics, Affinities and Kernels section of the user guide for further details.\n",
    "\n",
    "The [sklearn.metrics module](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) includes score functions, performance metrics and pairwise metrics and distance computations.\n",
    "\n",
    "Here is the list I need to use from this lib:\n",
    "1. [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report)\n",
    "1. [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix)\n",
    "1. [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)\n",
    "\n",
    "\n",
    "[3.3.2.7. Classification report](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-report)\n",
    "\n",
    "The classification_report function builds a text report showing the main classification metrics. Here is a small example with custom target_names and inferred labels:\n",
    "\n",
    "**sklearn.metrics.classification_report(y_true, y_pred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')**[source](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3c5a9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.67      0.78        39\n",
      "           1       0.73      0.95      0.82        37\n",
      "\n",
      "    accuracy                           0.80        76\n",
      "   macro avg       0.83      0.81      0.80        76\n",
      "weighted avg       0.83      0.80      0.80        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the sklearn.metric additiona evaluation and reporting methods\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# now print the classification report y_true is y_test, y_pred is well y_preds\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9865da22",
   "metadata": {},
   "source": [
    "From this lib I need [confusion matrix (here is the user guide on it)](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix). Also here is [wikipedia page on cofusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix).\n",
    "\n",
    "**sklearn.metrics.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)**\n",
    "\n",
    "returns: \n",
    "    C: ndarray of shape (n_classes, n_classes)\n",
    "\n",
    "Confusion matrix whose i-th row and j-th column entry indicates the number of samples with true label being i-th class and predicted label being j-th class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2b66a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26, 13],\n",
       "       [ 2, 35]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the confusion matrix with y_true = y_test and y_pred = y_preds\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cb9847",
   "metadata": {},
   "source": [
    "Next is the [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)\n",
    "\n",
    "**sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)**\n",
    "\n",
    "Returns: score: float\n",
    "\n",
    "If normalize == True, return the fraction of correctly classified samples (float), else returns the number of correctly classified samples (int).\n",
    "\n",
    "The best performance is 1 with normalize == True and the number of samples with normalize == False.\n",
    "\n",
    "*see the example in the source guide*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c49d0075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8026315789473685"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the accuracy_score with y_true = y_test and y_pred = y_preds\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cd96fe",
   "metadata": {},
   "source": [
    "#### 5. Experiment to improve\n",
    "The first model we build is often referred  to as baseline.\n",
    "\n",
    "Once we have got a baseline model, like we have here, it is important to remember, this is often not the final model we will use. \n",
    "\n",
    "The next step in the workflow is to try to improve upon your baseline model.\n",
    "\n",
    "To do this there are two ways to look at it: \n",
    "1. Form a model perspective \n",
    "1. From the data perspective\n",
    "\n",
    "From model perspective maybe would involves things such as using a more complex model or tuning current model's hyper-parameters.\n",
    "\n",
    "From data perspective, this may involves collecting more data or improving the data quality. This will give better chance of the model to learn the pattern within.\n",
    "\n",
    "If you are already working on an existing dataset, it is often easier to try a series of model perspective experiments first then turn to data perspective if you are not getting the result you are looking for. This is sounds like our current case where we alreasy have heart disease data frame.\n",
    "\n",
    "One thing you should be aware of is if you are tuning a model's hyper-parameters in a series of experiments, your results should always be **cross-validated**. \n",
    "\n",
    "Cross validation is a way of making sure that results you are getting are consistent across your training and test dataset. This must validate the use of multiple versions of training and test sets rather than just pure luck because of the order the training and test sets were created.\n",
    "- try different hyper-parameters\n",
    "- All different parameters should be cross validated\n",
    "    - **CAUTION:** beware of cross validation for time series problems\n",
    "\n",
    "Different models you use will have different hyper-parameters you can tune. For the case of our model the Random Forrest Classifier, we will start trying different values for n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "293f00ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying model with 10 estimators...\n",
      "Model accuracy on test: 81.57894736842105%\n",
      "\n",
      "trying model with 20 estimators...\n",
      "Model accuracy on test: 82.89473684210526%\n",
      "\n",
      "trying model with 30 estimators...\n",
      "Model accuracy on test: 78.94736842105263%\n",
      "\n",
      "trying model with 40 estimators...\n",
      "Model accuracy on test: 81.57894736842105%\n",
      "\n",
      "trying model with 50 estimators...\n",
      "Model accuracy on test: 81.57894736842105%\n",
      "\n",
      "trying model with 60 estimators...\n",
      "Model accuracy on test: 80.26315789473685%\n",
      "\n",
      "trying model with 70 estimators...\n",
      "Model accuracy on test: 85.52631578947368%\n",
      "\n",
      "trying model with 80 estimators...\n",
      "Model accuracy on test: 81.57894736842105%\n",
      "\n",
      "trying model with 90 estimators...\n",
      "Model accuracy on test: 77.63157894736842%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try different numbers of estimators (trees) ... (no cross-validation)\n",
    "# why does it need the random seed?\n",
    "# this is important since we will compare this results with the one with cross validation\n",
    "np.random.seed(42)\n",
    "\n",
    "# we will make estimators of (10, 20, 30, 40, 50, 60, 70, 80, 90)\n",
    "for i in range(10,100,10):\n",
    "    print(f\"trying model with {i} estimators...\")\n",
    "    model = RandomForestClassifier(n_estimators=i).fit(x_train, y_train)\n",
    "    print(f\"Model accuracy on test: {model.score(x_test, y_test) * 100}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48b467be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying model with 10 estimators...\n",
      "Model accuracy on test: 81.57894736842105%\n",
      "Cross-validation score: 78.53551912568305%\n",
      "\n",
      "trying model with 20 estimators...\n",
      "Model accuracy on test: 84.21052631578947%\n",
      "Cross-validation score: 79.84699453551912%\n",
      "\n",
      "trying model with 30 estimators...\n",
      "Model accuracy on test: 80.26315789473685%\n",
      "Cross-validation score: 80.50819672131148%\n",
      "\n",
      "trying model with 40 estimators...\n",
      "Model accuracy on test: 81.57894736842105%\n",
      "Cross-validation score: 82.15300546448088%\n",
      "\n",
      "trying model with 50 estimators...\n",
      "Model accuracy on test: 82.89473684210526%\n",
      "Cross-validation score: 81.1639344262295%\n",
      "\n",
      "trying model with 60 estimators...\n",
      "Model accuracy on test: 81.57894736842105%\n",
      "Cross-validation score: 83.47540983606557%\n",
      "\n",
      "trying model with 70 estimators...\n",
      "Model accuracy on test: 80.26315789473685%\n",
      "Cross-validation score: 81.83060109289617%\n",
      "\n",
      "trying model with 80 estimators...\n",
      "Model accuracy on test: 78.94736842105263%\n",
      "Cross-validation score: 82.81420765027322%\n",
      "\n",
      "trying model with 90 estimators...\n",
      "Model accuracy on test: 82.89473684210526%\n",
      "Cross-validation score: 82.81967213114754%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we will compare the different numbers of estimators but with cross validation\n",
    "# import the coross validation score lib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# re-seeding the random generator and set the same number series\n",
    "np.random.seed(42)\n",
    "\n",
    "# rerun similar test but adding cross validation\n",
    "for i in range(10,100,10):\n",
    "    print(f\"trying model with {i} estimators...\")\n",
    "    model = RandomForestClassifier(n_estimators=i).fit(x_train, y_train)\n",
    "    print(f\"Model accuracy on test: {model.score(x_test, y_test) * 100}%\")\n",
    "    print(f\"Cross-validation score: {np.mean(cross_val_score(model, x_data, y_data, cv=5)) * 100}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ab1c1",
   "metadata": {},
   "source": [
    "***NOTE***: the cross_val_score function return an array. Thus the score must be averaged in order to make some practical scale. Therefore, it is needed numpy means to average the cross_val_score return.\n",
    "\n",
    "[learn more on cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)\n",
    "\n",
    "question: why does it build their own model each time trying new amount of estimator? Can it just use the clf object made earlier and see the changes from there?\n",
    "\n",
    "Another way to find the best estimator is using [GridSearchCV sklearn model](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df29f961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 80}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we use GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# re-seeding the random number generator\n",
    "np.random.seed(42)\n",
    "\n",
    "# the main part for the grid search is defining the param_grid\n",
    "# param_grid is a dict type with str as key and list as value\n",
    "# the key (str) is the parameter of the estimator to be iterate and tested to find the most optimal parameter\n",
    "param_grid = {'n_estimators': [i for i in range(10,100,10)]}\n",
    "\n",
    "# preparing the grid\n",
    "grid = GridSearchCV(RandomForestClassifier(),param_grid, cv=5)\n",
    "\n",
    "# use the grid to fit the whole data\n",
    "grid.fit(x_data, y_data)\n",
    "\n",
    "# find the best grid\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d41f820b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=80)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we use the parameter in the grid.best_params_ to be used to the selected estimator (in this case Random Forest Classifier)\n",
    "# then set the parameter on n_estimator in that estimator using the grid.best_params_\n",
    "# then we set our clf (we set earlier in our first attempt to model the whole data) according to the best_estimator_ \n",
    "clf = grid.best_estimator_\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d29b8c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the best model to fit\n",
    "clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "934b04b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8157894736842105"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rate the score for the new fit model\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c6ac0b",
   "metadata": {},
   "source": [
    "#### 6. Save a model for someone else to use\n",
    "When you've done a few experiments and you're happy with how your model is doing, you'll likely want someone else to be able to use it.\n",
    "\n",
    "This may come in the form of a teammate or colleague trying to replicate and validate your results or through a customer using your model as part of a service or apllication you offer.\n",
    "\n",
    "Saving a model also allows you to reuse it later without having to go through retrianing it. Which is helpful, especially when your training times start to increase. \n",
    "\n",
    "You can save a scikit-learn model using [Python's built-in pickle module](https://docs.python.org/3/library/pickle.html) which serialize objects.\n",
    "\n",
    "In this session I will try to serialize model which tried in number of estimator. Note that the last model is made the number of estimator of 90.\n",
    "\n",
    "The score for the last model with number of estimator of 90 is 86.8421052631579% which we will use to validate the model once it was re-loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5051b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use pickle to serialize the model (only the model not the whole notebook)\n",
    "import pickle\n",
    "\n",
    "# save the model called model (the one iterated for number of estimator 10 to 100)\n",
    "pickle.dump(model, open('random_forest_model_1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756d927",
   "metadata": {},
   "source": [
    "***NOTE***: After this command is run you can confirm that random_forest_model_1.pkl file is created and available in the same folder as this ipynb file location.\n",
    "\n",
    "Let's validate by loading the model form the random_forest_model_1.pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfac402d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=90)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = pickle.load(open('random_forest_model_1.pkl', 'rb'))\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9013c54",
   "metadata": {},
   "source": [
    "***NOTE***: The loaded model is the same type and having the same n_estimators parameter as the latest model (which is 90). But we still need to verify the model to be consistent which means it must have the same performace score as the orignal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25d9d775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8289473684210527"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the loaded_model consistency\n",
    "# the score should match the model(n_estimator=90) score which is 86.8421052631579%\n",
    "loaded_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea2dc4c",
   "metadata": {},
   "source": [
    "***NOTE***: the score when testing the x_test and y_test is 0.868421052631579 which is the same as 86.8421052631579%.\n",
    "\n",
    "Meaning the loaded_model is consistent as the serialized original model(n_estimators=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769fa4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
